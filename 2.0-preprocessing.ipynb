{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on GPU = False\n",
      "loading of datasets done\n"
     ]
    }
   ],
   "source": [
    "from libraries import * \n",
    "from preprocessing import downloading_loading_processed_files\n",
    "from utils import enframe\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# selecting GPU if possible\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"running on GPU = {str(device) == 'cuda'}\")\n",
    "\n",
    "# (down)loading split datasets, can be run twice if kernel dies 1st time\n",
    "train_set, validation_set, test_set = downloading_loading_processed_files(\n",
    "    downsampling=False)\n",
    "print(f\"loading of datasets done\")\n",
    "\n",
    "# setting up computational parameters\n",
    "if device == \"cuda\":\n",
    "    num_workers, pin_memory = 4, True\n",
    "else:\n",
    "    num_workers, pin_memory = 0, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all element in dataset are shpae 78*13\n",
    "# about 2,8 to 2,9% of the inputs have nan in it (preprocessing problematic: dataset should be filtered\n",
    "def remove_nan_in(dataset):\n",
    "    not_nan_entries = []\n",
    "    for i, (lmfcc, sample_rate, label, speaker_id, utterance_number) in enumerate(dataset):\n",
    "        if not np.isnan(lmfcc).any():\n",
    "            not_nan_entries.append(i)\n",
    "    return np.array(dataset)[not_nan_entries]\n",
    "\n",
    "train_set = remove_nan_in(train_set)\n",
    "validation_set = remove_nan_in(validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.pcolormesh(train_set[10][0].T);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set up of dataloader done\n"
     ]
    }
   ],
   "source": [
    "def pad_sequence(batch):\n",
    "    \"\"\" \n",
    "    desc: make all tensor in a batch the same length as the longest sequence by padding with zeros \n",
    "    \"\"\"\n",
    "    batch = [torch.from_numpy(item) for item in batch]\n",
    "    batch = torch.nn.utils.rnn.pad_sequence(batch, batch_first=True, padding_value=0.)\n",
    "    return batch.permute(0, 2, 1)  # in each tensor, target first, tensor second\n",
    "\n",
    "# encoding each word using its index in the list of labels\n",
    "def label_to_index(word):\n",
    "    \"\"\" \n",
    "    desc: return the position of the word in labels \n",
    "    \"\"\"\n",
    "    return torch.tensor(labels.index(word))\n",
    "    \n",
    "def collate_fn(batch):\n",
    "    \"\"\" \n",
    "    desc: turn audio's list batch into two batch tensors for model \n",
    "    \"\"\"\n",
    "    tensors, targets = [], []\n",
    "\n",
    "    # Gather in lists, and encode labels as indices\n",
    "    for waveform, _, label, *_ in batch:\n",
    "        tensors += [waveform]\n",
    "        targets += [label_to_index(label)]\n",
    "\n",
    "    # Group the list of tensors into a batched tensor\n",
    "    tensors = pad_sequence(tensors)\n",
    "    targets = torch.stack(targets)\n",
    "    return tensors, targets\n",
    "\n",
    "    \n",
    "# sets in to dataloaders\n",
    "batch_size = 16\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_set, batch_size=batch_size, shuffle=True, collate_fn=collate_fn,\n",
    "    num_workers=num_workers, pin_memory=pin_memory)\n",
    "validation_loader = torch.utils.data.DataLoader(\n",
    "    validation_set, batch_size=batch_size, shuffle=False, drop_last=False,\n",
    "    collate_fn=collate_fn, num_workers=num_workers, pin_memory=pin_memory)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    validation_set, batch_size=batch_size, shuffle=False, drop_last=False,\n",
    "    collate_fn=collate_fn, num_workers=num_workers, pin_memory=pin_memory)\n",
    "print(f\"set up of dataloader done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MODEL (adapted from there: https://www.kaggle.com/code/talmanr/cnn-with-pytorch-using-mel-features/notebook)\n",
    "class CnnAudioNet(nn.Module):\n",
    "    def __init__(self,NumClasses):\n",
    "        super(CnnAudioNet,self).__init__()\n",
    "        self.NumClasses = NumClasses\n",
    "        self.Fc_features = 128\n",
    "        self.C1 = nn.Conv2d(1,32,3,padding=1)\n",
    "        self.C2 = nn.Conv2d(32,32,5,padding=1)\n",
    "        self.BN1 = nn.BatchNorm2d(32)  # change size of batch norm?\n",
    "        self.fc1 = nn.Linear(1536,128)\n",
    "        self.fc2 = nn.Linear(128, self.NumClasses)\n",
    "        self.maxpool1 = nn.MaxPool2d(2,2)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        \n",
    "        self.C3 = nn.Conv2d(32,64,5,padding=1)\n",
    "        self.BN2 = nn.BatchNorm2d(64)\n",
    "\n",
    "\n",
    "    def forward(self,x):        \n",
    "        x = F.relu(self.BN1(self.C1(x)))\n",
    "        x = self.maxpool1(F.relu(self.BN1(self.C2(x))))\n",
    "        \n",
    "        x = self.maxpool1(F.relu(self.BN2(self.C3(x))))\n",
    "                \n",
    "        x = (x.view(-1,np.prod(x.shape[1:]))) # self.dropout\n",
    "        # dim to know here for fully connected\n",
    "        # print(x.shape)\n",
    "        x = self.dropout(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "labels = sorted(list(set(datapoint[2] for datapoint in train_set)))  \n",
    "\n",
    "model = CnnAudioNet(len(labels))\n",
    "model.to(device)  # convert initialized model to CUDA optimized model\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([34, 21,  0, 34, 24, 16, 32, 10, 18, 14, 17, 10,  2, 28, 26, 11])\n"
     ]
    }
   ],
   "source": [
    "# run first with - F.nll_loss 10 iterations, than +F.nll_loss 20 iterations, it works starts to have results, lr 1e-3\n",
    "model.train()\n",
    "\n",
    "train_loss_history, nb_epochs = [], 20\n",
    "valid_loss_history = []\n",
    "for epoch in tqdm(range(nb_epochs)):\n",
    "    # train and eval train loss\n",
    "    train_loss = 0.0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "\n",
    "        print(target)\n",
    "        target = target.to(device)\n",
    "        data = (data-data.mean())/data.std()\n",
    "        data = data.to(device, dtype=torch.float)\n",
    "        output = model(data.unsqueeze(1)) #bug\n",
    "        _, pred = torch.max(output,1)\n",
    "\n",
    "        # negative log-likelihood for tensor of size (batch x 1 x n_output)\n",
    "        loss = F.nll_loss(output, target)\n",
    "\n",
    "        optimizer.zero_grad()  \n",
    "        loss.backward()  \n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "    print('Train batch loss: {:.6f},'.format(train_loss))\n",
    "    train_loss_history.append(loss)\n",
    "    \n",
    "#     # eval val loss\n",
    "#     with torch.no_grad():\n",
    "#         model.eval()\n",
    "#         valid_loss = 0 \n",
    "#         for data, target in validation_loader:\n",
    "            \n",
    "#             target = target.to(device)\n",
    "#             data = data.to(device, dtype=torch.float)\n",
    "#             output = model(data.unsqueeze(1))\n",
    "#             _,pred = torch.max(output,1)\n",
    "            \n",
    "#             loss = F.nll_loss(output, target)\n",
    "#             valid_loss += loss.item()\n",
    "#     valid_loss_history.append(valid_loss)\n",
    "            \n",
    "            \n",
    "\n",
    "    \n",
    "plt.plot(train_loss_history, \"r--\", label=\"train_loss\")\n",
    "# plt.plot(valid_loss_history, \"g--\", label=\"val_loss\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from preprocessing import Preprocessing  # run first with - F.nll_loss 10 iterations, than +F.nll_loss 20 iterations, it works starts to have results, lr 1e-3\n",
    "\n",
    "\n",
    "\n",
    "processor = Preprocessing(train_set, validation_set, test_set)\n",
    "model.train()\n",
    "\n",
    "train_loss_history, nb_epochs = [], 20\n",
    "valid_loss_history = []\n",
    "for epoch in tqdm(range(nb_epochs)):\n",
    "    \n",
    "    # train and eval train loss\n",
    "    train_loss = 0.0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "\n",
    "        print(target)\n",
    "        target = target.to(device)\n",
    "        data = (data-data.mean())/data.std()\n",
    "\n",
    "        data = data.to(device, dtype=torch.float)\n",
    "        output = model(data.unsqueeze(1))\n",
    "        _, pred = torch.max(output,1)\n",
    "\n",
    "        # negative log-likelihood for tensor of size (batch x 1 x n_output)\n",
    "        loss = F.nll_loss(output, target)\n",
    "\n",
    "        optimizer.zero_grad()  \n",
    "        loss.backward()  \n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "    print('Train batch loss: {:.6f},'.format(train_loss))\n",
    "    train_loss_history.append(loss)\n",
    "    \n",
    "#     # eval val loss\n",
    "#     with torch.no_grad():\n",
    "#         model.eval()\n",
    "#         valid_loss = 0 \n",
    "#         for data, target in validation_loader:\n",
    "            \n",
    "#             target = target.to(device)\n",
    "#             data = data.to(device, dtype=torch.float)\n",
    "#             output = model(data.unsqueeze(1))\n",
    "#             _,pred = torch.max(output,1)\n",
    "            \n",
    "#             loss = F.nll_loss(output, target)\n",
    "#             valid_loss += loss.item()\n",
    "#     valid_loss_history.append(valid_loss)\n",
    "            \n",
    "            \n",
    "\n",
    "    \n",
    "plt.plot(train_loss_history, \"r--\", label=\"train_loss\")\n",
    "# plt.plot(valid_loss_history, \"g--\", label=\"val_loss\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(train_set[100][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
